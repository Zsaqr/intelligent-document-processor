# ğŸ“„ Intelligent Document Processor (OCR + NER)

An end-to-end **intelligent document processing** tool that combines:

- ğŸ§¾ **Optical Character Recognition (OCR)** â€“ extract text from images / scanned documents  
- ğŸ§  **Named Entity Recognition (NER)** â€“ detect and categorize entities (persons, organizations, locations, dates, etc.) in text  

Built with **Python**, **Tesseract OCR**, **OpenCV**, **spaCy**, and **Streamlit**.

---

## ğŸš€ Features

- Upload images of scanned documents or handwritten notes
- Run **OCR** to extract machine-readable text
- Run **NER** to automatically detect entities like:
  - `PERSON`, `ORG`, `GPE`, `DATE`, `TIME`, etc.
- Interactive **Streamlit web UI** with:
  - `OCR Only` mode
  - `NER Only` mode
  - `OCR â†’ NER Pipeline` (end-to-end flow)
- Highlight entities directly inside the text
- Basic support for **Arabic OCR** (via Tesseract `ara` language) in addition to English

> **Note:**  
> NER is currently **English-only** using `spaCy (en_core_web_sm)`.  
> Arabic text can be extracted via OCR, but NER for Arabic is not yet implemented.

---

## ğŸ§± Tech Stack

- **Language:** Python  
- **Web UI:** Streamlit  
- **OCR:** Tesseract OCR + pytesseract + OpenCV  
- **NLP / NER:** spaCy  
- **Image handling:** Pillow  
- **Data display:** pandas  

---

## ğŸ“‚ Project Structure

```text
intelligent-document-processor/
â”‚
â”œâ”€ app.py              # Main Streamlit app (UI + logic)
â”œâ”€ ocr_utils.py        # OCR helper functions (Tesseract + OpenCV)
â”œâ”€ ner_utils.py        # NER helper functions (spaCy)
â”œâ”€ requirements.txt    # Python dependencies
â””â”€ README.md           # Project documentation
ğŸ› ï¸ Installation
1ï¸âƒ£ Clone the repository
bash
Copy code
git clone https://github.com/<your-username>/intelligent-document-processor.git
cd intelligent-document-processor
2ï¸âƒ£ Create and activate a virtual environment (recommended)
bash
Copy code
python -m venv .venv
.venv\Scripts\activate   # On Windows

# On Linux / macOS:
# source .venv/bin/activate
3ï¸âƒ£ Install Python dependencies
bash
Copy code
python -m pip install -r requirements.txt
This installs:

streamlit

pytesseract

opencv-python

Pillow

spacy

pandas

4ï¸âƒ£ Install spaCy English model
bash
Copy code
python -m spacy download en_core_web_sm
ğŸ”¡ Tesseract OCR Setup
1ï¸âƒ£ Install Tesseract
Download and install Tesseract OCR for your OS (Windows / Linux / macOS).

On Windows, it is commonly installed to:

text
Copy code
C:\Program Files\Tesseract-OCR\
Make sure you can run tesseract from the terminal (add it to PATH if needed).

2ï¸âƒ£ Install Arabic language data (optional but recommended)
To enable Arabic OCR, ensure that ara.traineddata exists in your Tesseract tessdata folder, e.g.:

text
Copy code
C:\Program Files\Tesseract-OCR\tessdata\ara.traineddata
If it's missing, download ara.traineddata from the official Tesseract tessdata repository and place it into the tessdata folder.

3ï¸âƒ£ Configure Tesseract path in code
In ocr_utils.py, the Tesseract executable and tessdata path are set explicitly (you can adjust if your path is different):

python
Copy code
pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"
os.environ["TESSDATA_PREFIX"] = r"C:\Program Files\Tesseract-OCR\tessdata"
â–¶ï¸ Running the App
From the project root:

bash
Copy code
streamlit run app.py
Then open the URL shown in the terminal (usually http://localhost:8501) in your browser.

ğŸ§ª How to Use
1ï¸âƒ£ OCR â†’ NER Pipeline (End-to-End)
In the sidebar, select â€œOCR â†’ NER Pipelineâ€ mode.

Upload an image containing text (scanned document / printed text / clear handwriting).

Select OCR language:

eng â†’ English

ara â†’ Arabic (requires ara.traineddata)

eng+ara â†’ mixed content

Click â€œRun OCRâ€ to extract text.

Scroll down to the NER section.

Click â€œRun NERâ€ to detect entities in the extracted text.

View:

A table of extracted entities.

The text with highlighted spans for each entity.

2ï¸âƒ£ OCR Only
Select â€œOCR Onlyâ€ from the sidebar.

Upload an image and choose OCR language.

Click â€œRun OCRâ€.

View the extracted text in the text area.

3ï¸âƒ£ NER Only
Select â€œNER Onlyâ€ from the sidebar.

Paste or type any English text into the input box.

Click â€œRun NERâ€.

View:

A table listing entities (text, label, start_char, end_char).

The same text with entities highlighted and labeled inline.

ğŸ“Œ Limitations & Future Work
âœ… OCR:

English: supported

Arabic: supported via Tesseract language data (quality depends on image quality and font)

âœ… NER:

English: supported using spaCy (en_core_web_sm)

âŒ Arabic NER:

Not yet implemented (future enhancement: use CAMeL Tools, Stanza, or a HuggingFace Arabic NER model)

Possible future improvements:

Add Arabic NER model for detecting entities in Arabic text.

Support for PDF uploads with multi-page OCR.

Add export to CSV / JSON for detected entities.

Add Dockerfile for easier deployment.

ğŸ“š Example Use Cases
Automating processing of scanned contracts and documents.

Extracting structured data (names, organizations, locations, dates) from reports.

Building a quick prototype for document understanding in an AI / NLP portfolio.

Using it as a base for more advanced document AI pipelines.

ğŸ‘¨â€ğŸ’» Author
Developed by Ziad Saqr as part of an AI / NLP portfolio project.

If you find this useful, feel free to â­ the repo and contribute with ideas or pull requests!

ğŸ‡¦ğŸ‡· Ù…Ù„Ø§Ø­Ø¸Ø© Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠ
Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ø¯Ù‡ Ù…Ø¹Ù…ÙˆÙ„ Ø¹Ø´Ø§Ù† ÙŠÙˆØ±Ù‘ÙŠ End-to-End Flow Ù„Ø·ÙŠÙ:

ØªØ§Ø®Ø¯ ØµÙˆØ±Ø©/Ø³ÙƒØ§Ù† â†’ ØªØ·Ù„Ø¹ Ù…Ù†Ù‡Ø§ Ù†Øµ (OCR)

ÙˆØ¨Ø¹Ø¯ÙŠÙ† ØªØ­Ù„Ù„ Ø§Ù„Ù†Øµ ÙˆØªØ³ØªØ®Ø±Ø¬ Ù…Ù†Ù‡ ÙƒÙŠØ§Ù†Ø§Øª Ù…Ù‡Ù…Ù‘Ø© (NER)

Ø§Ù„ÙƒÙˆØ¯ Ù‚Ø§Ø¨Ù„ Ù„Ù„ØªØ·ÙˆÙŠØ± Ø¨Ø³Ù‡ÙˆÙ„Ø©:

ØªÙ‚Ø¯Ø± ØªØ²ÙˆØ¯ Ù…ÙˆØ¯ÙŠÙ„Ø§Øª NER Ø¹Ø±Ø¨ÙŠØ©

Ø£Ùˆ ØªØ­Ø³Ù‘Ù† Ø§Ù„Ù€ preprocessing Ø¨ØªØ§Ø¹ Ø§Ù„ØµÙˆØ±

Ø£Ùˆ ØªØ¶ÙŠÙ export Ù„Ù„Ù†ØªØ§Ø¦Ø¬